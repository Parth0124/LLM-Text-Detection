{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c54d88-204e-4fb7-a340-03079004811f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is LLM generated: False\n",
      "Accuracy: 0.00\n",
      "\n",
      "Predictions saved to files:\n",
      "- Detailed JSON report: text_analysis_results_[timestamp].json\n",
      "- Predicted words CSV: predicted_words_[timestamp].csv\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "def initialize_model():\n",
    "    \"\"\"Initialize BERT model and tokenizer with proper configuration\"\"\"\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "   \n",
    "    model = AutoModelForMaskedLM.from_pretrained(\n",
    "        model_name,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False\n",
    "    )\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    return tokenizer, model\n",
    "\n",
    "def analyze_text_authenticity(paragraph, num_red_tokens=10):\n",
    "    \n",
    "    tokenizer, model = initialize_model()\n",
    "    \n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokenizer(paragraph, return_tensors=\"pt\")['input_ids'][0])\n",
    "\n",
    "    red_indices = np.random.choice(len(tokens), num_red_tokens, replace=False)\n",
    "    \n",
    "    # Mark tokens and create the masked version\n",
    "    marked_tokens = tokens.copy()\n",
    "    for idx in red_indices:\n",
    "        marked_tokens[idx] = '[MASK]'\n",
    "\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        ' '.join(marked_tokens),\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        mask_positions = inputs['input_ids'][0] == tokenizer.mask_token_id\n",
    "        \n",
    "        predictions = []\n",
    "        for pos in torch.where(mask_positions)[0]:\n",
    "            probs = torch.softmax(logits[0, pos], dim=-1)\n",
    "            top_probs, top_tokens = torch.topk(probs, k=5)\n",
    "            \n",
    "            original_token = tokens[red_indices[len(predictions)]]\n",
    "            predicted_token = tokenizer.convert_ids_to_tokens(top_tokens[0].item())\n",
    "            \n",
    "          \n",
    "            top_5_predictions = [\n",
    "                 {'token': tokenizer.convert_ids_to_tokens(top_tokens[i].item()), 'probability': top_probs[i].item()}\n",
    "                for i in range(5)\n",
    "            ]\n",
    "\n",
    "            \n",
    "            predictions.append({\n",
    "                'original': original_token,\n",
    "                'predicted': predicted_token,\n",
    "                'probability': top_probs[0].item(),\n",
    "                'is_match': original_token == predicted_token,\n",
    "                'top_5_predictions': top_5_predictions\n",
    "            })\n",
    "    \n",
    " \n",
    "    correct_predictions = sum(1 for p in predictions if p['is_match'])\n",
    "    total_predictions = len(predictions)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    \n",
    " \n",
    "    is_llm_generated = accuracy > 0.5\n",
    "    \n",
    "    results = {\n",
    "        'predictions': predictions,\n",
    "        'accuracy': accuracy,\n",
    "        'is_llm_generated': is_llm_generated,\n",
    "        'marked_text': ' '.join(marked_tokens),\n",
    "        'original_text': paragraph\n",
    "    }\n",
    "    \n",
    "    save_results(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_results(results):\n",
    "  \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "   \n",
    "    json_filename = f'text_analysis_results_{timestamp}.json'\n",
    "    with open(json_filename, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "   \n",
    "    csv_filename = f'predicted_words_{timestamp}.csv'\n",
    "    with open(csv_filename, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Original Word', 'Predicted Word', 'Probability', 'Is Match', \n",
    "                        'Top 5 Predictions'])\n",
    "        \n",
    "        for pred in results['predictions']:\n",
    "            top_5_str = ' | '.join([f\"{p['token']}({p['probability']:.3f})\" \n",
    "                                  for p in pred['top_5_predictions']])\n",
    "            writer.writerow([\n",
    "               pred['original'],\n",
    "                pred['predicted'],\n",
    "                f\"{pred['probability']:.3f}\",\n",
    "                pred['is_match'],\n",
    "                top_5_str\n",
    "            ])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_paragraph = \"\"\"My name is Parth. I am a boy. I love to watch football and formula 1. My favourite team is Real Madrid in football and Mercedes in Formula 1. I play at a center forward position in football. I love voding. I have built many projects. Some of them are House marketplace and Github finder along wit IMDB sentiment analysis and Churn prediction. I am learning generative ai. I am searching for internships to work in dr=uring the summer holidays.\"\"\"\n",
    "    results = analyze_text_authenticity(sample_paragraph)\n",
    "    print(f\"Is LLM generated: {results['is_llm_generated']}\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.2f}\")\n",
    "    print(\"\\nPredictions saved to files:\")\n",
    "    print(\"- Detailed JSON report: text_analysis_results_[timestamp].json\")\n",
    "    print(\"- Predicted words CSV: predicted_words_[timestamp].csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc55cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
