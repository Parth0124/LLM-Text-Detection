{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "287f8c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/parthabhang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce8e48f",
   "metadata": {},
   "source": [
    "## Using BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c54d88-204e-4fb7-a340-03079004811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "def initialize_model():\n",
    "    \"\"\"Initialize BERT model and tokenizer with proper configuration\"\"\"\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    model = AutoModelForMaskedLM.from_pretrained(\n",
    "        model_name,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    return tokenizer, model\n",
    "\n",
    "def preprocess_text(paragraph):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = re.findall(r'\\w+|[^\\w\\s]', paragraph.lower()) \n",
    "    return words, stop_words\n",
    "\n",
    "def analyze_text_authenticity(paragraph, num_red_tokens=10):\n",
    "    tokenizer, model = initialize_model()\n",
    "\n",
    "    words, stop_words = preprocess_text(paragraph)\n",
    "\n",
    "    if num_red_tokens > len(words):\n",
    "        num_red_tokens = len(words)\n",
    "\n",
    "    word_indices = [i for i, word in enumerate(words) if re.match(r'\\w+', word) and word not in stop_words]\n",
    "    mask_indices = np.random.choice(word_indices, num_red_tokens, replace=False)\n",
    "\n",
    "    marked_words = words.copy()\n",
    "    for idx in mask_indices:\n",
    "        marked_words[idx] = '[MASK]'\n",
    "\n",
    "    marked_text = ' '.join(marked_words)\n",
    "\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        marked_text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        mask_positions = inputs['input_ids'][0] == tokenizer.mask_token_id\n",
    "\n",
    "        predictions = []\n",
    "        for pos in torch.where(mask_positions)[0]:\n",
    "            probs = torch.softmax(logits[0, pos], dim=-1)\n",
    "            top_probs, top_tokens = torch.topk(probs, k=5)\n",
    "            original_word = words[mask_indices[len(predictions)]]\n",
    "            predicted_word = tokenizer.convert_ids_to_tokens(top_tokens[0].item())\n",
    "\n",
    "            top_5_predictions = [\n",
    "                {'token': tokenizer.convert_ids_to_tokens(top_tokens[i].item()), 'probability': top_probs[i].item()}\n",
    "                for i in range(5)\n",
    "            ]\n",
    "\n",
    "            predictions.append({\n",
    "                'original': original_word,\n",
    "                'predicted': predicted_word,\n",
    "                'probability': top_probs[0].item(),\n",
    "                'is_match': original_word == predicted_word,\n",
    "                'top_5_predictions': top_5_predictions\n",
    "            })\n",
    "\n",
    "    correct_predictions = sum(1 for p in predictions if p['is_match'])\n",
    "    total_predictions = len(predictions)\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "\n",
    "    is_llm_generated = accuracy > 0.5\n",
    "\n",
    "    results = {\n",
    "        'predictions': predictions,\n",
    "        'accuracy': accuracy,\n",
    "        'is_llm_generated': is_llm_generated,\n",
    "        'marked_text': marked_text,\n",
    "        'original_text': ' '.join(words)\n",
    "    }\n",
    "\n",
    "    save_results(results)\n",
    "    return results\n",
    "\n",
    "def save_results(results):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    json_filename = f'text_analysis_results_{timestamp}.json'\n",
    "    with open(json_filename, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    csv_filename = f'predicted_words_{timestamp}.csv'\n",
    "    with open(csv_filename, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Original Word', 'Predicted Word', 'Probability', 'Is Match', \n",
    "                         'Top 5 Predictions'])\n",
    "\n",
    "        for pred in results['predictions']:\n",
    "            top_5_str = ' | '.join([f\"{p['token']}({p['probability']:.3f})\" \n",
    "                                     for p in pred['top_5_predictions']])\n",
    "            writer.writerow([\n",
    "                pred['original'],\n",
    "                pred['predicted'],\n",
    "                f\"{pred['probability']:.3f}\",\n",
    "                pred['is_match'],\n",
    "                top_5_str\n",
    "            ])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_paragraph = \"\"\"In the quiet solitude of the evening, as the last rays of the sun dipped below the horizon, the world seemed to slow, giving way to a sense of peace that had been absent throughout the day. The soft rustling of leaves in the breeze and the distant chirping of crickets were the only sounds that filled the air, creating a symphony of tranquility. It was in these fleeting moments, between the fading light and the onset of darkness, that one could feel a deep connection to the rhythm of nature, reminding them of the simple beauty that exists when the world pauses to breathe.\"\"\"\n",
    "\n",
    "    results = analyze_text_authenticity(sample_paragraph)\n",
    "    print(f\"\\nParagraph with masked words:\\n{results['marked_text']}\")\n",
    "    print(f\"\\nIs LLM generated: {results['is_llm_generated']}\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.2f}\")\n",
    "    print(\"\\nPredictions saved to files:\")\n",
    "    print(\"- Detailed JSON report: text_analysis_results_[timestamp].json\")\n",
    "    print(\"- Predicted words CSV: predicted_words_[timestamp].csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95fd79d",
   "metadata": {},
   "source": [
    "## Using GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbfa793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/parthabhang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping empty tokenization for context: ''\n",
      "\n",
      "Paragraph with masked words:\n",
      "in the quiet solitude of the evening , as the last rays of the sun dipped below the horizon , the world seemed to slow , giving way to a sense of peace that had been absent throughout the day . the soft rustling of leaves in the breeze and the distant chirping of crickets were the only sounds that filled the air , creating a symphony of tranquility . it was in these fleeting moments , between the fading light and the onset of darkness , that one could feel a deep connection to the rhythm of nature , reminding them of the simple beauty that exists when the world pauses to breathe .\n",
      "\n",
      "Is LLM generated: False\n",
      "Accuracy: 0.01\n",
      "\n",
      "Predictions saved to files:\n",
      "- Detailed JSON report: text_analysis_results_[timestamp].json\n",
      "- Predicted words CSV: predicted_words_[timestamp].csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Ensure that stopwords are downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def initialize_model():\n",
    "    \"\"\"Initialize GPT-2 model and tokenizer with proper configuration\"\"\"\n",
    "    model_name = \"gpt2\"\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # Use EOS token as padding token\n",
    "\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "    return tokenizer, model\n",
    "\n",
    "def preprocess_text(paragraph):\n",
    "    \"\"\"Preprocess text by removing stop words and tokenizing the text\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = re.findall(r'\\w+|[^\\w\\s]', paragraph.lower()) \n",
    "    return words, stop_words\n",
    "\n",
    "def analyze_text_authenticity(paragraph):\n",
    "    \"\"\"Analyze text by predicting next word and determining authenticity\"\"\"\n",
    "    tokenizer, model = initialize_model()\n",
    "\n",
    "    words, stop_words = preprocess_text(paragraph)\n",
    "\n",
    "    # Tokenize the original text for input\n",
    "    inputs = tokenizer(paragraph, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    marked_words = words.copy()\n",
    "\n",
    "    # Tokenize and predict the next word for each word in the paragraph\n",
    "    predictions = []\n",
    "    for i in range(len(words)):\n",
    "        # Create input text with the first i words\n",
    "        context_text = ' '.join(words[:i])\n",
    "        \n",
    "        # Tokenize the context text\n",
    "        context_input = tokenizer(context_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        \n",
    "        # Check if the input is not empty\n",
    "        if context_input['input_ids'].size(1) == 0:\n",
    "            print(f\"Skipping empty tokenization for context: '{context_text}'\")\n",
    "            continue\n",
    "        \n",
    "        context_input_ids = context_input['input_ids'].squeeze(0).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Get model predictions for the next word\n",
    "            outputs = model(context_input_ids)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Get the top 5 predicted next words (topk)\n",
    "            topk_values, topk_indices = torch.topk(logits[0, -1], k=5, dim=-1)\n",
    "\n",
    "            top_5_predictions = []\n",
    "            for idx, val in zip(topk_indices, topk_values):\n",
    "                predicted_word = tokenizer.decode(idx)\n",
    "                probability = torch.softmax(val, dim=-1).item()\n",
    "                top_5_predictions.append({\n",
    "                    'token': predicted_word,\n",
    "                    'probability': probability\n",
    "                })\n",
    "\n",
    "            original_word = words[i]\n",
    "            predicted_word = tokenizer.decode(topk_indices[0])  # The top prediction\n",
    "            predictions.append({\n",
    "                'original': original_word,\n",
    "                'predicted': predicted_word,\n",
    "                'is_match': original_word == predicted_word,\n",
    "                'top_5_predictions': top_5_predictions\n",
    "            })\n",
    "\n",
    "    # Calculate accuracy\n",
    "    correct_predictions = sum(1 for p in predictions if p['is_match'])\n",
    "    total_predictions = len(predictions)\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "\n",
    "    is_llm_generated = accuracy > 0.5  # Determine if the text is likely generated by a language model\n",
    "\n",
    "    results = {\n",
    "        'predictions': predictions,\n",
    "        'accuracy': accuracy,\n",
    "        'is_llm_generated': is_llm_generated,\n",
    "        'marked_text': ' '.join(marked_words),\n",
    "        'original_text': paragraph\n",
    "    }\n",
    "\n",
    "    save_results(results)\n",
    "    return results\n",
    "\n",
    "def save_results(results):\n",
    "    \"\"\"Save results to JSON and CSV files\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Save results to a JSON file\n",
    "    json_filename = f'text_analysis_results_{timestamp}.json'\n",
    "    with open(json_filename, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    # Save predictions to a CSV file\n",
    "    csv_filename = f'predicted_words_{timestamp}.csv'\n",
    "    with open(csv_filename, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Original Word', 'Predicted Word', 'Is Match', 'Top 5 Predictions'])\n",
    "\n",
    "        for pred in results['predictions']:\n",
    "            top_5_str = ' | '.join([f\"{p['token']}({p['probability']:.4f})\" \n",
    "                                     for p in pred['top_5_predictions']])\n",
    "            writer.writerow([\n",
    "                pred['original'],\n",
    "                pred['predicted'],\n",
    "                pred['is_match'],\n",
    "                top_5_str\n",
    "            ])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample paragraph for testing\n",
    "    sample_paragraph = \"\"\"In the quiet solitude of the evening, as the last rays of the sun dipped below the horizon, the world seemed to slow, giving way to a sense of peace that had been absent throughout the day. The soft rustling of leaves in the breeze and the distant chirping of crickets were the only sounds that filled the air, creating a symphony of tranquility. It was in these fleeting moments, between the fading light and the onset of darkness, that one could feel a deep connection to the rhythm of nature, reminding them of the simple beauty that exists when the world pauses to breathe.\"\"\"\n",
    "\n",
    "    # Analyze text authenticity\n",
    "    results = analyze_text_authenticity(sample_paragraph)\n",
    "    print(f\"\\nParagraph with masked words:\\n{results['marked_text']}\")\n",
    "    print(f\"\\nIs LLM generated: {results['is_llm_generated']}\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.2f}\")\n",
    "    print(\"\\nPredictions saved to files:\")\n",
    "    print(\"- Detailed JSON report: text_analysis_results_[timestamp].json\")\n",
    "    print(\"- Predicted words CSV: predicted_words_[timestamp].csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
